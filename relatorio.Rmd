---
title: "Desempenho Fundos"
author: "Bruno"
date: "18/04/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE )
```


```{r}

library(tidyverse)
library(readxl)
library(tidymodels)
library(nlme)
library(lubridate)
library(shadowtext)
library(vip)
library(multilevelmod)


```


# Separando treino/validação e teste


```{r}

dados <- read_excel("dados/base_fundos.xlsx") %>% 
    janitor::clean_names() %>% 
    mutate(
        across(
            .cols = c(ap_in, mov_min, sharp_12, vol_total, sald_perm),
            .fns = as.numeric
        )
    ) %>% 
    mutate(
        percent_tx_perf = str_extract(percent_tx_perf, "[0-9]*") %>% as.numeric() 
    ) %>% 
    mutate(
        tempo_de_vida = 2021 - year(fundacao)
    ) %>% 
    filter(
      !is.na(sharp_12),
      !is.na(anbima)
    )


dado_separado <- initial_split(
  data = dados, 
  prop = 4/5
)


# Create data frames for the two sets:
dado_treino <- training(dado_separado)
dado_teste  <- testing(dado_separado)



```


# Análise exploratória


```{r}

skimr::skim(dado_treino)


```

# Criando o modelo random forest


```{r}

modelo_randforest <- rand_forest(
    trees = tune(),
    mtry = tune(),
    min_n = tune()
) %>% 
    set_engine(
        "ranger", importance = "impurity"
    ) %>% 
    set_mode(
        "regression"
    )
    

    

```


Aqui só tem variáveis que são características dos fundos, que por premisa consideramos conhecidas antes do momento em que o desepeho estã sendo medido. Incluímos a vol, porque consideramos que a vol é uma característica do fundo


```{r}


receita_pre <- dado_treino %>% 
  recipe(sharp_12 ~ 
           ap_in + 
           mov_min + 
           sald_perm + 
           resg_cot + 
           resg_liq + 
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
           pl20
        ) %>% 
  step_impute_mean(all_numeric_predictors(), -all_outcomes()) 
  # step_corr(all_predictors()) %>% 
  # step_center(all_predictors(), -all_outcomes()) %>% 
  # step_scale(all_predictors(), -all_outcomes()) 

```


fluxo de trabalho com o modelo e a receita de pré procesamento. A random forest funciona bem com atributos que não estão na msma escala, por isso não normalizamos


```{r}

fluxo_rf <- workflow() %>% 
    add_model(
        modelo_randforest    
    ) %>% 
  add_recipe(
    receita_pre
  ) 

```


grid de hiperparâmetros: combinações de hiperparãmetros a serem testados


```{r}

grid_rf = grid_regular(
    mtry(range = c(2, 8)), # número de atributos testados a cada quebra das árvores de decisão
    trees(range = c(100, 300 )), #número de ãrvores de decis]apo da floresta
    min_n(range = c(1, 20)), #tamanho limite pra qiuuebra do nó
    levels = 3
)


```

```{r}

set.seed(1984)

folds <- vfold_cv(dado_treino, v = 5)


```




```{r}

resultado_rf <- fluxo_rf %>% 
 tune_grid(resamples = folds, 
            grid = grid_rf)
    


```


https://en.wikipedia.org/wiki/Root-mean-square_deviation

https://en.wikipedia.org/wiki/Coefficient_of_determination



```{r}


performance <-  resultado_rf %>%
  collect_metrics() 

```

```{r}

perf_accuracy <- performance %>% 
  filter(
    .metric == "rsq"
  )


```


```{r}

ggplot(perf_accuracy) +
  geom_tile(
    aes(
      y = factor(trees),
      x = factor(mtry),
      fill = mean
    ),
    show.legend = FALSE
  ) +
  geom_shadowtext(
    aes(
      y = factor(trees),
      x = factor(mtry),
      label= percent(mean, accuracy = 0.01)   
    ),
    color = "black",
    bg.colour = "darkgray"
  ) +
  scale_fill_gradient(
    low = "lightgray",
    high = "darkgreen"
  ) +
  facet_wrap(
    ~min_n
  ) +
  theme_minimal()


```




```{r}

melhor_modelo <- resultado_rf %>%
  select_best(metric = "rsq")  
  
workflow_final <- fluxo_rf %>%
  finalize_workflow(melhor_modelo)



```





```{r}

fit_final <- workflow_final %>%
  last_fit(dado_separado)



```



```{r}


performance_teste <- fit_final %>% 
  collect_metrics()


performance_teste

```


```{r}

fit_final %>%  extract_fit_parsnip() %>% 
  vip() +
  theme_minimal()


```







# Criando o modelo elasticnet


```{r}

modelo_elastic <- linear_reg(
    penalty = tune(),
    mixture = tune()
) %>% 
    set_engine(
        "glmnet"
    ) %>% 
    set_mode(
        "regression"
    )
    


```

O modelo elasticnet conjuga lasso e ridge. Esses modelos penalizam o resultado pela existência (lasso, groso modo) e pelo tamanho (ridge) dos coeficientes. Para que esse modelo funcione bem, é preciso normalizar e centralizar as variáveis



```{r}


receita_pre_elastic <- dado_treino %>% 
  recipe(sharp_12 ~ 
           ap_in + 
           mov_min + 
           sald_perm + 
           resg_cot + 
           resg_liq + 
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
            pl20
        ) %>% 
  step_impute_mean(all_numeric_predictors(), -all_outcomes()) %>% 
  # step_corr(all_predictors()) %>% 
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes())

```



```{r}

fluxo_elastic <- workflow() %>% 
    add_model(
        modelo_elastic    
    ) %>% 
  add_recipe(
    receita_pre_elastic
  ) 

```



```{r}

grid_elastic = grid_regular(
    penalty(),
    mixture(),
    levels = 5
)


```




```{r}

resultado_elastic <- fluxo_elastic %>% 
 tune_grid(resamples = folds, 
            grid = grid_elastic)
    


```


```{r}


performance_elastic <-  resultado_elastic %>%
  collect_metrics() 

```

```{r}

perf_accuracy_elastic <- performance_elastic %>% 
  filter(
    .metric == "rsq"
  )


```


```{r}

ggplot(perf_accuracy_elastic) +
  geom_tile(
    aes(
      y = factor(penalty),
      x = factor(mixture),
      fill = mean
    ),
    show.legend = FALSE
  ) +
  geom_shadowtext(
    aes(
      y = factor(penalty),
      x = factor(mixture),
      label= percent(mean, accuracy = 0.01)   
    ),
    color = "black",
    bg.colour = "darkgray"
  ) +
  scale_fill_gradient(
    low = "lightgray",
    high = "darkgreen"
  ) +
  theme_minimal()


```




```{r}

melhor_modelo_elastic <- resultado_elastic %>%
  select_best(metric = "rsq")  
  
workflow_final_elastic <- fluxo_elastic %>%
  finalize_workflow(melhor_modelo_elastic)



```





```{r}

fit_final_elastic <- workflow_final_elastic %>%
  last_fit(dado_separado)



```



```{r}


performance_teste_elastic <- fit_final_elastic %>% 
  collect_metrics()

```


Os coeficientes são relativos ao desvio padrão de cada variável explicativa, já que elas foram normalizadas.



```{r}

fit_final_elastic$.workflow[[1]] %>% 
  pull_workflow_fit() %>% 
  tidy()

```





# Criando o modelo lm


```{r}

modelo_lm <- linear_reg(
) %>% 
    set_engine(
        "lm"
    ) %>% 
    set_mode(
        "regression"
    )
    


```


```{r}


receita_lm <- dado_treino %>% 
  recipe(sharp_12 ~ 
           ap_in + 
           mov_min + 
           sald_perm + 
           resg_cot + 
           resg_liq + 
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
            pl20
        ) %>% 
  step_impute_mean(all_numeric_predictors(), -all_outcomes()) 

```



```{r}

fluxo_lm <- workflow() %>% 
    add_model(
        modelo_lm    
    ) %>% 
  add_recipe(
    receita_lm
  ) 

```



```{r}

grid_lm = grid_regular(
    penalty(),
    mixture(),
    levels = 1
)


```




```{r}

resultado_lm <- fluxo_lm %>% 
 tune_grid(resamples = folds, 
            grid = grid_lm)
    
    


```


```{r}


performance_lm <-  resultado_lm %>%
  collect_metrics() 

```

```{r}

perf_accuracy_lm <- performance_lm %>% 
  filter(
    .metric == "rsq"
  )



perf_accuracy_lm

```



```{r}

melhor_modelo_lm <- resultado_lm %>%
  select_best(metric = "rsq")  
  
workflow_final_lm <- fluxo_lm %>%
  finalize_workflow(melhor_modelo_lm)



```





```{r}

fit_final_lm <- workflow_final_lm %>%
  last_fit(dado_separado)



```


Este coeficiente está referente ao valor original da variável


```{r}

fit_final_lm$.workflow[[1]] %>% 
  pull_workflow_fit() %>% 
  tidy()


```

# Criando o modelo multinivel


```{r}

modelo_lmer <- linear_reg(
) %>% 
    set_engine(
        "lmer"
    ) %>% 
    set_mode(
        "regression"
    )
    


```


```{r}


receita_lmer <- dado_treino %>% 
  recipe(sharp_12 ~ 
           ap_in + 
           mov_min + 
           sald_perm + 
           resg_cot + 
           resg_liq + 
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
           pl20 +
           anbima 
        ) 



dados_anbima <- dados %>% 
    mutate(
        tipo_anbima = case_when(
            str_detect(anbima, "Ações") ~ "Acoes",
            str_detect(anbima, "Renda Fixa") ~ "Renda Fixa",
            str_detect(anbima, "Multimercado") ~ "Multimercado",
            TRUE ~ "Multimercado"
        )
    )


# mixed_model_fit <- 
#   linear_reg() %>% set_engine("lmer") %>% 
#   fit(sharp_12 ~ 
           ap_in +
           mov_min +
           sald_perm +
           resg_cot +
           resg_liq +
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
           pl20 +
#            (tipo_anbima | vol_total)  , data = dados_anbima)


mixed_model_fit <-
  linear_reg() %>% 
  set_engine("lme",  random = ~ 1 | tipo_anbima) %>%
  fit(sharp_12 ~
           ap_in +
           mov_min +
           sald_perm +
           resg_cot +
           resg_liq +
           tx_adm +
           percent_tx_perf +
           tempo_de_vida +
           vol_total +
           pl20 +
           tipo_anbima + vol_total  , data = dados_anbima %>% drop_na()  )



mixed_model_fit %>% 
    extract_fit_engine()


MuMIn::r.squaredGLMM(mixed_model_fit$fit)



lm_fit <-
  linear_reg() %>% 
  set_engine("lm") %>%
  fit(sharp_12 ~
           ap_in +
           mov_min +
           sald_perm +
           resg_cot +
           resg_liq +
           tx_adm +
           percent_tx_perf +
           poly(tempo_de_vida, 2) +
           vol_total +
           pl20 +
           pl20 * ap_in +
           tipo_anbima + 
           vol_total  , data = dados_anbima %>% drop_na()  )


summary(lm_fit$fit)





```



```{r}

fluxo_lm <- workflow() %>% 
    add_model(
        modelo_lm    
    ) %>% 
  add_recipe(
    receita_lm
  ) 

```



```{r}

grid_lm = grid_regular(
    penalty(),
    mixture(),
    levels = 1
)


```




```{r}

resultado_lm <- fluxo_lm %>% 
 tune_grid(resamples = folds, 
            grid = grid_lm)
    
    


```


```{r}


performance_lm <-  resultado_lm %>%
  collect_metrics() 

```

```{r}

perf_accuracy_lm <- performance_lm %>% 
  filter(
    .metric == "rsq"
  )



perf_accuracy_lm

```



```{r}

melhor_modelo_lm <- resultado_lm %>%
  select_best(metric = "rsq")  
  
workflow_final_lm <- fluxo_lm %>%
  finalize_workflow(melhor_modelo_lm)



```





```{r}

fit_final_lm <- workflow_final_lm %>%
  last_fit(dado_separado)



```


Este coeficiente está referente ao valor original da variável


```{r}

fit_final_lm$.workflow[[1]] %>% 
  pull_workflow_fit() %>% 
  tidy()


```




```{r}


performance_teste_lm <- fit_final_lm %>% 
  collect_metrics()


performance_predictions_lm <- fit_final_lm %>% 
  collect_predictions()


```

# Decision tree


```{r}


dt <- decision_tree(
  min_n = 3,
  tree_depth = 30) %>% 
  set_mode("regression") %>% 
  set_engine("rpart")


```



```{r}




fluxo_dt <- workflow() %>% 
    add_model(
        dt    
    ) %>% 
  add_recipe(
    receita_pre
  ) 


dt_cls_fit <- fluxo_dt %>% fit(dado_treino)




```






```{r}

class(dt_cls_fit$fit$fit$fit)

rpart.plot::rpart.plot(dt_cls_fit$fit$fit$fit  )


```




```{r}


Modelo <- lme(fixed = R36M ~ TPMRC + RLIQ + TADM + TXPM + PL,
                                    random = ~ RLIQ,
                                    data = datan2,
                                    method = "REML")




```












